{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace \"/User/your-service-account-key.json\" with the actual path to your service account key JSON file\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = "*******",
    "\n",
    "# Now you can use Google Cloud client libraries, and they will use the credentials from the specified JSON file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from google.cloud import language_v1\n",
    "import numpy\n",
    "import tweepy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def content(contentc):\n",
    "    list_of_categories=[]\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    text_content = contentc\n",
    "    type_ = language_v1.Document.Type.PLAIN_TEXT\n",
    "    language = \"en\"\n",
    "    document = {\"content\": text_content, \"type_\": type_, \"language\": language}\n",
    "    encoding_type = language_v1.EncodingType.UTF8\n",
    "\n",
    "    content_categories_version = (\n",
    "        language_v1.ClassificationModelOptions.V2Model.ContentCategoriesVersion.V2)\n",
    "\n",
    "    # Analyze sentiment\n",
    "    response1 = client.analyze_sentiment(\n",
    "        request={\"document\": document, \"encoding_type\": encoding_type}\n",
    "    )\n",
    "\n",
    "    # Analyze content categories\n",
    "    response2 = client.classify_text(\n",
    "        request={\n",
    "            \"document\": document,\n",
    "            \"classification_model_options\": {\n",
    "                \"v2_model\": {\"content_categories_version\": content_categories_version}\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    a = set()\n",
    "\n",
    "    for sentence in response1.sentences:\n",
    "        if sentence.sentiment.score > 0.2:\n",
    "            #print(f\"Sentence text: {sentence.text.content}\")\n",
    "#             print(f\"Sentence sentiment score: {sentence.sentiment.score}\")\n",
    "            #print(\"//////////////\")\n",
    "            #print(response2)\n",
    "            #print(\"//////////////\")\n",
    "            for category in response2.categories:\n",
    "                if category.confidence > 0.2:\n",
    "                    category_name = category.name\n",
    "                    list_of_categories.append(category_name)\n",
    "                    \n",
    "    \n",
    "    return list_of_categories\n",
    "\n",
    "# Get your Twitter API credentials and enter them here\n",
    "consumer_key = \"**********",
    "consumer_secret = \"*********"\n",
    "access_key = \"*************\"\n",
    "access_secret = \"************\"\n",
    "bearer_token = \"*****************\"\n",
    "\n",
    "def get_user_tweets_analyzed(username):\n",
    "    # Tokens\n",
    "    api = tweepy.Client(\n",
    "        bearer_token=bearer_token,\n",
    "        consumer_key=consumer_key,\n",
    "        consumer_secret=consumer_secret,\n",
    "        access_token=access_key,\n",
    "        access_token_secret=access_secret\n",
    "    )\n",
    "\n",
    "    user = api.get_user(username=username)\n",
    "    user_id = user.data.id\n",
    "\n",
    "    tweets = api.get_users_tweets(id=user_id, max_results=5)\n",
    "    all_categories = get_categories_for_tweets(tweets)\n",
    "    list_of_tuple_username_categories = [(username, i) for i in all_categories]\n",
    "    return list_of_tuple_username_categories\n",
    "    print(\"Username\")\n",
    "   \n",
    "    \n",
    "def deep_flatten(lst):\n",
    "    flattened_list = []\n",
    "    for i in lst:\n",
    "        if isinstance(i, list):\n",
    "            flattened_list.extend(deep_flatten(i))\n",
    "        else:\n",
    "            flattened_list.append(i)\n",
    "    return flattened_list\n",
    "\n",
    "def get_categories_for_tweets(tweets):\n",
    "    total_categories =[]\n",
    "    for i in range(len(tweets.data)):\n",
    "         tweet_content = tweets.data[i].text\n",
    "         categories = content(tweet_content)\n",
    "         total_categories.append(categories)\n",
    "    return deep_flatten(total_categories)\n",
    "\n",
    "        \n",
    "def get_main_user_tweets(username):\n",
    "    # Tokens\n",
    "    global_result = []\n",
    "    main_user_result = get_user_tweets_analyzed(username)\n",
    "    #print(\"Main user result \")\n",
    "    global_result.append(main_user_result)\n",
    "    #print(main_user_result)\n",
    "        \n",
    "    liked_tweets_result=get_liked_tweets_for(username)\n",
    "    global_result.append(liked_tweets_result)\n",
    "    return deep_flatten(global_result)\n",
    "\n",
    "def get_liked_tweets_for(username):\n",
    "    function_result=[]\n",
    "    api = tweepy.Client(\n",
    "    bearer_token=bearer_token,\n",
    "    consumer_key=consumer_key,\n",
    "    consumer_secret=consumer_secret,\n",
    "    access_token=access_key,\n",
    "    access_token_secret=access_secret)    \n",
    "    user= api.get_user(username=username)\n",
    "    #print(user)    \n",
    "    user_id= user.data.id\n",
    "    #print(user[0])\n",
    "    response = api.get_liked_tweets(id=user_id, expansions='author_id',max_results=5)\n",
    "#     print(response.includes)\n",
    "    for i in range(len(response.includes[\"users\"])):\n",
    "        #print(response.includes[\"users\"][i].username)\n",
    "        liked_user_result=get_user_tweets_analyzed(response.includes[\"users\"][i].username)\n",
    "        #print(\"Liked user result \",response.includes[\"users\"][i].username)\n",
    "        function_result.append(liked_user_result)\n",
    "        #print(liked_user_result)\n",
    "    return function_result\n",
    "\n",
    "# print(\"Enter one username\")\n",
    "# user = input(\"Enter username:\")\n",
    "# df_input= get_main_user_tweets(user)\n",
    "\n",
    "# print(\"******************\")\n",
    "# print(df_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def create_dataframe(df_input):\n",
    "    # Process the categories to extract the first part and tally counts\n",
    "    processed_data = []\n",
    "    for user, category in df_input:\n",
    "    # Extract the main category\n",
    "        main_category = category.split('/')[1]  # Split by '/' and take the second element\n",
    "        processed_data.append((user, main_category))\n",
    "\n",
    "# Convert processed data into a DataFrame\n",
    "    df_processed = pd.DataFrame(processed_data, columns=['User', 'Category'])\n",
    "\n",
    "# Create a pivot table with users as rows, categories as columns, and counts as values\n",
    "    pivot_df = pd.pivot_table(df_processed, index='User', columns='Category', aggfunc=len, fill_value=0)\n",
    "    return pivot_df\n",
    "\n",
    "# df=create_dataframe(df_input)\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "def create_recommendation(df):\n",
    "    # Convert the DataFrame into a sparse matrix for efficiency\n",
    "    sparse_df = sparse.csr_matrix(df.values)\n",
    "\n",
    "    # Calculate the cosine similarity matrix\n",
    "    cosine_sim = cosine_similarity(sparse_df, dense_output=False)\n",
    "\n",
    "    # Convert the cosine similarity matrix to a DataFrame for easier manipulation\n",
    "    cosine_sim_df = pd.DataFrame(cosine_sim.toarray(), index=df.index, columns=df.index)\n",
    "\n",
    "    # Get the similarity values for the first user (Alice) with all users\n",
    "    similarity_scores = cosine_sim_df.iloc[0]\n",
    "\n",
    "    # Sort the users based on similarity scores, excluding the first user herself\n",
    "    sorted_users = similarity_scores.sort_values(ascending=False)[1:]\n",
    "\n",
    "    # Identify the top N similar users for recommendations\n",
    "    top_n_users = sorted_users.head(3).index\n",
    "\n",
    "    # Compile recommendations from top N similar users\n",
    "    recommendations = pd.Series(dtype='float64')\n",
    "    for user in top_n_users:\n",
    "        # Get categories that the first user hasn't interacted with yet (rated 0)\n",
    "        unseen_categories = df.loc['CapstoneP003'][df.loc['CapstoneP003'] == 0].index\n",
    "        # Add the unseen categories rated by the similar user to the recommendations\n",
    "        recommendations=pd.concat([recommendations, df.loc[user, unseen_categories]])\n",
    "        #recommendations = recommendations.append(df.loc[user, unseen_categories])\n",
    "\n",
    "    # Group recommendations by category and calculate the average rating from the top N users\n",
    "    recommendations = recommendations.groupby(recommendations.index).mean().sort_values(ascending=False)\n",
    "    print(f\"Recommended categories for CapstoneP003 based on top similar users' preferences: {recommendations.index.tolist()}\")\n",
    "    return recommendations\n",
    "    \n",
    "\n",
    "# create_recommendation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [14/Mar/2024 01:44:50] \"POST /recommendations HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CapstoneP003', '/Food & Drink/Cooking & Recipes/Cuisines'), ('CapstoneP003', '/Food & Drink/Food/Meat & Seafood'), ('CapstoneP003', '/Food & Drink/Cooking & Recipes/Cuisines'), ('CapstoneP003', '/Online Communities/Social Networks'), ('CapstoneP003', '/Sports/Team Sports/Basketball'), ('CapstoneP003', '/Online Communities/Social Networks'), ('sachin_rt', '/Hobbies & Leisure/Special Occasions/Holidays & Seasonal Events'), ('sachin_rt', '/Sports/Team Sports/Cricket'), ('sachin_rt', '/Online Communities/Social Networks'), ('sachin_rt', '/Hobbies & Leisure/Special Occasions/Holidays & Seasonal Events'), ('sachin_rt', '/Sports/Team Sports/Cricket'), ('sachin_rt', '/Online Communities/Social Networks'), ('sachin_rt', '/Sports/Team Sports/Cricket'), ('sachin_rt', '/News/Sports News'), ('sachin_rt', '/Sports/Team Sports/Cricket'), ('sachin_rt', '/News/Sports News'), ('sachin_rt', '/Sports/Team Sports/Cricket'), ('sachin_rt', '/News/Sports News'), ('sachin_rt', '/Sports/Team Sports/Cricket'), ('sachin_rt', '/News/Sports News'), ('sachin_rt', '/Arts & Entertainment/Movies/Bollywood & South Asian Film'), ('sachin_rt', '/Arts & Entertainment/Movies/Movie Reference'), ('sachin_rt', '/Arts & Entertainment/TV & Video/TV Shows & Programs'), ('sachin_rt', '/Arts & Entertainment/Movies/Bollywood & South Asian Film'), ('sachin_rt', '/Arts & Entertainment/Movies/Movie Reference'), ('sachin_rt', '/Arts & Entertainment/TV & Video/TV Shows & Programs'), ('sachin_rt', '/Arts & Entertainment/Movies/Bollywood & South Asian Film'), ('sachin_rt', '/Arts & Entertainment/Movies/Movie Reference'), ('sachin_rt', '/Arts & Entertainment/TV & Video/TV Shows & Programs'), ('sachin_rt', '/Sports/Team Sports/Cricket'), ('sachin_rt', '/Arts & Entertainment/Events & Listings/Live Sporting Events'), ('sachin_rt', '/News/Sports News'), ('sachin_rt', '/Sports/Team Sports/Cricket'), ('sachin_rt', '/Arts & Entertainment/Events & Listings/Live Sporting Events'), ('sachin_rt', '/News/Sports News'), ('md_irfan10', '/Hobbies & Leisure/Special Occasions/Holidays & Seasonal Events'), ('md_irfan10', '/Online Communities/Photo & Video Sharing/Photo & Image Sharing'), ('md_irfan10', '/Shopping/Gifts & Special Event Items/Greeting Cards'), ('md_irfan10', '/Hobbies & Leisure/Special Occasions/Holidays & Seasonal Events'), ('md_irfan10', '/Online Communities/Photo & Video Sharing/Photo & Image Sharing'), ('md_irfan10', '/Shopping/Gifts & Special Event Items/Greeting Cards'), ('md_irfan10', '/Online Communities/Social Networks'), ('md_irfan10', '/Online Communities/Social Networks'), ('md_irfan10', '/Online Communities/Photo & Video Sharing/Photo & Image Sharing'), ('md_irfan10', '/Online Communities/Social Networks'), ('md_irfan10', '/Hobbies & Leisure/Special Occasions/Holidays & Seasonal Events'), ('md_irfan10', '/Online Communities/Social Networks'), ('md_irfan10', '/Online Communities/Photo & Video Sharing/Photo & Image Sharing'), ('md_irfan10', '/Shopping/Gifts & Special Event Items/Greeting Cards'), ('md_irfan10', '/Hobbies & Leisure/Special Occasions/Holidays & Seasonal Events'), ('md_irfan10', '/Online Communities/Social Networks'), ('md_irfan10', '/Online Communities/Photo & Video Sharing/Photo & Image Sharing'), ('md_irfan10', '/Shopping/Gifts & Special Event Items/Greeting Cards')]\n",
      "Category      Arts & Entertainment  Food & Drink  Hobbies & Leisure  News  \\\n",
      "User                                                                        \n",
      "CapstoneP003                     0             3                  0     0   \n",
      "md_irfan10                       0             0                  4     0   \n",
      "sachin_rt                       11             0                  2     6   \n",
      "\n",
      "Category      Online Communities  Shopping  Sports  \n",
      "User                                                \n",
      "CapstoneP003                   2         0       1  \n",
      "md_irfan10                    10         4       0  \n",
      "sachin_rt                      2         0       8  \n",
      "Recommended categories for CapstoneP003 based on top similar users' preferences: ['Arts & Entertainment', 'Hobbies & Leisure', 'News', 'Shopping']\n",
      "Arts & Entertainment    5.5\n",
      "Hobbies & Leisure       3.0\n",
      "News                    3.0\n",
      "Shopping                2.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from google.cloud import language_v1\n",
    "import numpy\n",
    "import tweepy\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define the API route\n",
    "@app.route('/recommendations', methods=['POST'])\n",
    "def get_recommendations():\n",
    "    # Get the username from the request\n",
    "    username = request.json['username']\n",
    "    df_input= get_main_user_tweets(username)\n",
    "    print(df_input)\n",
    "    df=create_dataframe(df_input)\n",
    "    print(df.head())\n",
    "    # Call the function to get the recommendations for the username\n",
    "    user_recommendations = create_recommendation(df)\n",
    "    print(user_recommendations.head())\n",
    "    # Convert the recommendations to a JSON response\n",
    "    response = {'username': username, 'recommendations': user_recommendations.index.tolist()}\n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
